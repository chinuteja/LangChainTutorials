{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7333acc9",
   "metadata": {},
   "source": [
    "## Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffbef252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.output_parsers import StrOutputParser,JsonOutputParser\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema,PydanticOutputParser\n",
    "from groq import Groq\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.schema.runnable import RunnableParallel,RunnableBranch, RunnableLambda,RunnableSequence,RunnablePassthrough\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "from typing import TypedDict,Annotated,Optional,Literal\n",
    "from pydantic import BaseModel, EmailStr, Field\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1818d725",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGroq(\n",
    "        groq_api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "        model_name=\"Gemma2-9b-It\",\n",
    "        temperature=0.5 ## this is creative parameter\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc2dd4f",
   "metadata": {},
   "source": [
    "## Runnable Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bad2534f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the Statue of Liberty get a tan?\n",
      "\n",
      "Because she was always standing in the sun! ðŸ‡ºðŸ‡¸â˜€ï¸  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template = \"Tell me a joke about {topic}\",\n",
    "    input_variables = [\"topic\"]\n",
    ")\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = RunnableSequence(prompt,model,parser)\n",
    "result = chain.invoke({\"topic\":\"USA\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "334a8241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The joke plays on the double meaning of \"neural network.\"\n",
      "\n",
      "* **Literal Meaning:** In poker, a \"network\" of players might be a group of people who work together to win.  \n",
      "\n",
      "* **AI Meaning:**  A \"neural network\" is a type of artificial intelligence system inspired by the structure of the human brain. These networks are very good at learning patterns and making decisions, which is crucial for a good poker player.\n",
      "\n",
      "\n",
      "The humor comes from the unexpected connection between these two meanings. We initially think the joke is about a group of AI players, but it turns out to be about a single AI using its advanced learning capabilities to excel at the game.  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "prompt_1 = PromptTemplate(\n",
    "    template = \"Tell me a joke about {topic}\",\n",
    "    input_variables = [\"topic\"]\n",
    ")\n",
    "\n",
    "prompt_2 = PromptTemplate(\n",
    "    template = \"Explain the following joke {text}\",\n",
    "    input_variables = [\"text\"]\n",
    ")\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = RunnableSequence(prompt_1,model,parser,prompt_2,model,parser)\n",
    "result = chain.invoke({\"topic\":\"AI\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13cc082",
   "metadata": {},
   "source": [
    "## Runnable parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f0092a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tweet': \"AI is moving fast! ðŸ¤¯ From writing poems to composing music, it's blurring the lines between human & machine. What are your thoughts on the ethical implications of this rapid advancement? #AI #Technology #Future ðŸ¤–ðŸ§   \\n\\n\",\n",
       " 'LinkedIn': '##  Is AI a threat or an opportunity? ðŸ¤” \\n\\nThe rapid advancements in AI are sparking both excitement and concern.  While some fear job displacement and ethical dilemmas, others see AI as a powerful tool for innovation and progress. \\n\\n**What are your thoughts?**\\n\\nâœ…  Do you see AI as a force for good, driving efficiency and solving complex problems?\\n\\nâŒ  Are you worried about the potential negative impacts of AI on society and the workforce?\\n\\nLet\\'s have a constructive conversation about the future of AI and how we can harness its potential responsibly. \\n\\n#AI #ArtificialIntelligence #FutureofWork #Technology #Innovation #Ethics \\n\\n\\n**Optional additions:**\\n\\n* **Share a relevant article or news story about AI.**\\n* **Ask a specific question to encourage engagement, e.g., \"What are you doing to prepare for the AI-powered future?\"**\\n* **Tag relevant industry leaders or organizations.**\\n* **Include a personal anecdote about your experience with AI.**\\n'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_tweet = PromptTemplate(\n",
    "    template= 'Generate a tweet about {topic}',\n",
    "    input_variables = [\"topic\"]\n",
    ")\n",
    "\n",
    "prompt_linkedin = PromptTemplate(\n",
    "    template = 'Generate a LinkedIn post about {topic}',\n",
    "    input_variables = [\"topic\"]\n",
    ")\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "parallel_chain = RunnableParallel({\n",
    "    \"tweet\":RunnableSequence(prompt_tweet,model,parser),\n",
    "    \"LinkedIn\":RunnableSequence(prompt_linkedin,model,parser),\n",
    "})\n",
    "\n",
    "parallel_chain.invoke({\"topic\":\"AI\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd050ea",
   "metadata": {},
   "source": [
    "## Runnable Passthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f076ca7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'teja'}\n"
     ]
    }
   ],
   "source": [
    "passthrough = RunnablePassthrough()\n",
    "print(passthrough.invoke({\"name\":\"teja\"})) ## what ever is the input it gives the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8229542",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt_1 = PromptTemplate(\n",
    "    template = \"Tell me a joke about {topic}\",\n",
    "    input_variables = [\"topic\"]\n",
    ")\n",
    "\n",
    "prompt_2 = PromptTemplate(\n",
    "    template = \"Explain the following joke {text}\",\n",
    "    input_variables = [\"text\"]\n",
    ")\n",
    "\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e042f43a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why did the AI cross the road? \\n\\nTo prove it wasn't chicken! ðŸ”ðŸ¤–  \\n\\nLet me know if you'd like to hear another one! ðŸ˜„  \\n\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joke_generator_chain = RunnableSequence(prompt_1,model,parser)\n",
    "joke_generator_chain.invoke({\"topic\":\"AI\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77becea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'joke': 'Why was the AI so good at poker?\\n\\nBecause it had a neural network!  ðŸƒðŸ§   \\n\\n\\nLet me know if you want to hear another one! ðŸ˜Š  \\n',\n",
       " 'explanation': 'The joke plays on the double meaning of \"neural network.\" \\n\\n* **In AI:** A neural network is a complex computer system designed to mimic the structure and function of the human brain. It\\'s used for tasks like learning patterns, making predictions, and even playing games.\\n\\n* **In poker:**  \"Network\" can refer to a player\\'s ability to read other players and understand their strategies, essentially building a \"network\" of information about their opponents.\\n\\nThe joke suggests that the AI was good at poker because it had a powerful neural network (the AI kind), which allowed it to analyze players and make strategic decisions just like a human player with a strong poker network.  \\n\\n\\nLet me know if you\\'d like to hear another joke! I\\'m always up for a laugh. ðŸ˜„  \\n\\n'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joke_generator_chain = RunnableSequence(prompt_1,model,parser)\n",
    "parallel_chain = RunnableParallel({\n",
    "    \"joke\":RunnablePassthrough(),\n",
    "    \"explanation\":RunnableSequence(prompt_2,model,parser)\n",
    "    \n",
    "})\n",
    "\n",
    "final_chain = RunnableSequence(joke_generator_chain,parallel_chain)\n",
    "final_chain.invoke({\"topic\":\"AI\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18496817",
   "metadata": {},
   "source": [
    "## Runnable Lamda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab3d8cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def word_counter(text):\n",
    "    return len(text.split())\n",
    "\n",
    "runnablewordcounter = RunnableLambda(word_counter)\n",
    "runnablewordcounter.invoke(\"hey whatsup ??\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489691fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'joke': \"Why was the AI so good at poker? \\n\\nBecause it had a neural network! ðŸƒ  ðŸ¤–  \\n\\n\\n\\nLet me know if you'd like to hear another one! ðŸ˜Š\\n\\n\",\n",
       " 'wordcount': 27}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joke_generator_chain = RunnableSequence(prompt_1,model,parser)\n",
    "parallel_chain = RunnableParallel({\n",
    "    \"joke\":RunnablePassthrough(),\n",
    "    \"wordcount\":RunnableLambda(word_counter)\n",
    "    \n",
    "})\n",
    "\n",
    "final_chain = RunnableSequence(joke_generator_chain,parallel_chain)\n",
    "final_chain.invoke({\"topic\":\"AI\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d60097",
   "metadata": {},
   "source": [
    "## Runnable Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12a915b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_report = PromptTemplate(\n",
    "    template = \"Write a detailed report on {topic}\",\n",
    "    input_variables = [\"topic\"]\n",
    ")\n",
    "\n",
    "prompt_summary = PromptTemplate(\n",
    "    template=\"Summarize the following text \\n {text}\",\n",
    "    input_variables = [\"text\"]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a12342d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This comprehensive report provides an overview of Artificial Intelligence (AI).  \n",
      "\n",
      "**Key points:**\n",
      "\n",
      "* **Definition:** AI involves developing computer systems capable of performing tasks that usually require human intelligence, like learning, problem-solving, and understanding language.\n",
      "\n",
      "* **Types:** AI encompasses narrow AI (designed for specific tasks), general AI (hypothetical human-level intelligence), super AI (hypothetical AI surpassing human intelligence), and subfields like machine learning, deep learning, and natural language processing.\n",
      "\n",
      "* **Applications:** AI is transforming industries like healthcare (diagnosis, drug discovery), finance (fraud detection), transportation (self-driving cars), retail (personalized recommendations), education (personalized learning), and manufacturing (predictive maintenance).\n",
      "\n",
      "* **Benefits:** AI offers increased efficiency, accuracy, innovation, personalized experiences, and improved safety.\n",
      "\n",
      "* **Challenges:**  Concerns include bias in algorithms, job displacement, privacy issues, security risks, and ethical dilemmas surrounding AI decision-making.\n",
      "\n",
      "* **Future:**  AI is expected to become more accessible, move towards edge computing, prioritize explainability, and be used for social good.\n",
      "\n",
      "\n",
      "The report emphasizes the need for responsible AI development and deployment, ensuring fairness, transparency, and accountability to maximize its benefits while mitigating potential risks. \n",
      "\n",
      "--------------\n",
      "171\n"
     ]
    }
   ],
   "source": [
    "report_generation_chain = RunnableSequence(prompt_report,model,parser)\n",
    "branch_chain = RunnableBranch(\n",
    "    (lambda x : len(x.split())>100,RunnableSequence(prompt_summary,model,parser)), ## if output is > 500  words we re summarize\n",
    "    RunnablePassthrough(),\n",
    "    # RunnableLambda(word_counter)\n",
    ")\n",
    "\n",
    "final_chain = RunnableSequence(report_generation_chain,branch_chain)\n",
    "output = final_chain.invoke({\"topic\":\"AI\"})\n",
    "print(output)\n",
    "print(\"--------------\")\n",
    "print(runnablewordcounter.invoke(output))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
